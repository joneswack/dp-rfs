{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random_features.polynomial_sketch import PolynomialSketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = torch.load('../../datasets/export/fashion_mnist/pytorch/train_fashion_mnist.pth')\n",
    "test_data, test_labels = torch.load('../../datasets/export/fashion_mnist/pytorch/test_fashion_mnist.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = torch.load('../../datasets/export/mnist/pytorch/train_mnist.pth')\n",
    "test_data, test_labels = torch.load('../../datasets/export/mnist/pytorch/test_mnist.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = torch.load('../../datasets/export/adult/pytorch/train_adult.pth')\n",
    "test_data, test_labels = torch.load('../../datasets/export/adult/pytorch/test_adult.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = torch.load('../../datasets/export/cod-rna/pytorch/train_cod-rna.pth')\n",
    "test_data, test_labels = torch.load('../../datasets/export/cod-rna/pytorch/test_cod-rna.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = torch.load('/home/jonas/python-projects/datasets/export/cifar10/pytorch/resnet34_final_conv_train.pth')\n",
    "test_data, test_labels = torch.load('/home/jonas/python-projects/datasets/export/cifar10/pytorch/resnet34_final_conv_test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree = 3\n",
    "# a = 2.\n",
    "# bias = 1.-2./a**2\n",
    "# lengthscale = a / np.sqrt(2.)\n",
    "degree = 3\n",
    "bias = 1\n",
    "lengthscale = np.sqrt(train_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reshape(len(train_data), -1)\n",
    "test_data = test_data.reshape(len(test_data), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.float()\n",
    "test_labels = test_labels.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max\n",
    "min_val = torch.min(train_data, 0)[0]\n",
    "val_range = torch.max(train_data, 0)[0] - min_val\n",
    "val_range[val_range == 0] = 1\n",
    "train_data = (train_data - min_val) / val_range\n",
    "test_data = (test_data - min_val) / val_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = train_data.mean(dim=0, keepdim=True)\n",
    "# std = train_data.std(dim=0, keepdim=True)\n",
    "# std[std==0] = 1.\n",
    "# train_data = (train_data - mean) / std\n",
    "# test_data = (test_data - mean) / std\n",
    "# train_data = train_data / std\n",
    "# test_data = test_data / std\n",
    "# unit norm\n",
    "train_data = train_data / train_data.norm(dim=1, keepdim=True)\n",
    "test_data = test_data / test_data.norm(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randint(len(train_data), (5000,))\n",
    "train_data = train_data[indices]\n",
    "train_labels = train_labels[indices]\n",
    "indices = torch.randint(len(test_data), (1000,))\n",
    "test_data = test_data[indices]\n",
    "test_labels = test_labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbf kernel\n",
    "# median_distance = torch.cdist(train_data, train_data).median()\n",
    "# lengthscale = median_distance\n",
    "# train_data = train_data / lengthscale\n",
    "# test_data = test_data / lengthscale\n",
    "# bias = 1.\n",
    "\n",
    "# squared_norm = (train_data**2).sum(dim=1)\n",
    "# prefactor_train = torch.exp(-squared_norm / 2.)\n",
    "\n",
    "# train_data = train_data / np.sqrt(degree)\n",
    "# test_data = test_data / np.sqrt(degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.627416997969522"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly kernel\n",
    "train_data = train_data / lengthscale\n",
    "test_data = test_data / lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder = torch.zeros(len(train_data), 512)\n",
    "placeholder[:, :train_data.shape[1]] = train_data\n",
    "placeholder[:, -1] = np.sqrt(bias)\n",
    "train_data = placeholder\n",
    "placeholder = torch.zeros(len(test_data), 512)\n",
    "placeholder[:, :test_data.shape[1]] = test_data\n",
    "placeholder[:, -1] = np.sqrt(bias)\n",
    "test_data = placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[train_labels==-1.] = 0\n",
    "test_labels[test_labels==-1.] = 0\n",
    "#train_labels = one_hot(train_labels.type(torch.LongTensor)).reshape(-1, 2).type(torch.FloatTensor)\n",
    "#test_labels = one_hot(test_labels.type(torch.LongTensor)).reshape(-1, 2).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cholesky_solve(y, L):\n",
    "    # L: lower triangular cholesky\n",
    "    return torch.triangular_solve(\n",
    "        torch.triangular_solve(y, L, upper=False)[0],\n",
    "        L.conj().t(), transpose=False, upper=True\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_linear_regression(train_features, train_labels, test_features, lam=0.1):\n",
    "    sigma_inv = train_features.t() @ train_features + torch.eye(len(train_features.t())) * lam\n",
    "    xTy = train_features.t() @ train_labels\n",
    "    L_sigma_inv = torch.cholesky(sigma_inv)\n",
    "    alpha = cholesky_solve(xTy, L_sigma_inv)\n",
    "    return test_features @ alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 0.01#0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 3\n",
      "Seed 0\n",
      "Seed 1\n",
      "Seed 2\n",
      "Seed 3\n",
      "Seed 4\n",
      "Seed 5\n",
      "Seed 6\n",
      "Seed 7\n",
      "Seed 8\n",
      "Seed 9\n",
      "Seed 10\n",
      "Seed 11\n",
      "Seed 12\n",
      "Seed 13\n",
      "Seed 14\n",
      "Seed 15\n",
      "Seed 16\n",
      "Seed 17\n",
      "Seed 18\n",
      "Seed 19\n"
     ]
    }
   ],
   "source": [
    "real_errors = []\n",
    "comp_errors = []\n",
    "\n",
    "real_accs = []\n",
    "comp_accs = []\n",
    "\n",
    "for degree in [degree]:\n",
    "    print('Degree', degree)\n",
    "    real_errors_cur = []\n",
    "    comp_errors_cur = []\n",
    "    \n",
    "    real_accs_cur = []\n",
    "    comp_accs_cur = []\n",
    "    \n",
    "    for seed in range(20):\n",
    "        print('Seed', seed)\n",
    "\n",
    "        # real sketch\n",
    "        feature_encoder = PolynomialSketch(\n",
    "            512, # data input dimension (power of 2 for srht projection_type)\n",
    "            2*512, # output dimension of the random sketch\n",
    "            degree=degree, # degree of the polynomial kernel\n",
    "            bias=0, # bias parameter of the polynomial kernel\n",
    "            lengthscale=1., # inverse scale of the data (like lengthscale for Gaussian kernel)\n",
    "            projection_type='srht',\n",
    "            hierarchical=False,\n",
    "            complex_weights=False,\n",
    "            full_cov=True,\n",
    "            convolute_ts=False,\n",
    "            complex_real=False\n",
    "        )\n",
    "\n",
    "        feature_encoder.resample()\n",
    "        projections_train = feature_encoder.forward(train_data)\n",
    "        projections_test = feature_encoder.forward(test_data)\n",
    "#         approx_kernel_real = projections_train @ projections_train.t()\n",
    "        predictions_real = solve_linear_regression(projections_train, train_labels, projections_test, lam=lam)\n",
    "#         projections_train = feature_encoder.forward(train_data)\n",
    "#         projections_test = feature_encoder.forward(test_data)\n",
    "#         projections_train = torch.hstack([projections_train.real, projections_train.imag])\n",
    "#         projections_test = torch.hstack([projections_test.real, projections_test.imag])\n",
    "        \n",
    "#         predictions_real = solve_linear_regression(projections_train, train_labels, projections_test, lam=0.1)\n",
    "        approx_kernel_real = projections_train @ projections_train.t()\n",
    "\n",
    "        # complex sketch\n",
    "        feature_encoder = PolynomialSketch(\n",
    "            512, # data input dimension (power of 2 for srht projection_type)\n",
    "            2*512, # output dimension of the random sketch\n",
    "            degree=degree, # degree of the polynomial kernel\n",
    "            bias=0, # bias parameter of the polynomial kernel\n",
    "            lengthscale=1., # inverse scale of the data (like lengthscale for Gaussian kernel)\n",
    "            projection_type='srht',\n",
    "            hierarchical=False,\n",
    "            complex_real=True,\n",
    "            complex_weights=False,\n",
    "            full_cov=True,\n",
    "            convolute_ts=False\n",
    "        )\n",
    "\n",
    "        feature_encoder.resample()\n",
    "        projections_train = feature_encoder.forward(train_data)\n",
    "        projections_test = feature_encoder.forward(test_data)\n",
    "#         projections_train = train_data\n",
    "#         projections_test = test_data\n",
    "        \n",
    "        predictions_comp = solve_linear_regression(projections_train, train_labels, projections_test, lam=lam)\n",
    "        approx_kernel_comp = projections_train @ projections_train.t()\n",
    "#         projections_train = feature_encoder.forward(train_data)\n",
    "#         projections_test = feature_encoder.forward(test_data)\n",
    "#         approx_kernel_comp = projections_train @ projections_train.t()\n",
    "#         predictions_comp = solve_linear_regression(projections_train, train_labels, projections_test, lam=0.1)\n",
    "\n",
    "        # reference kernel\n",
    "        ref_kernel = (train_data @ train_data.t())**degree\n",
    "#         pref = prefactor_train.unsqueeze(1) * prefactor_train.unsqueeze(0)\n",
    "#         ref_kernel = pref * (train_data @ train_data.t())**degree\n",
    "#         approx_kernel_comp *= pref\n",
    "#         approx_kernel_real *= pref\n",
    "\n",
    "        # error\n",
    "        real_error = (approx_kernel_real - ref_kernel).pow(2).sum().sqrt()\n",
    "        real_error /= ref_kernel.pow(2).sum().sqrt()\n",
    "\n",
    "        comp_error = (approx_kernel_comp - ref_kernel).pow(2).sum().sqrt()\n",
    "        comp_error /= ref_kernel.pow(2).sum().sqrt()\n",
    "\n",
    "        real_errors_cur.append(real_error.item())\n",
    "        comp_errors_cur.append(comp_error.item())\n",
    "        \n",
    "        real_acc = (predictions_real.argmax(dim=1) == test_labels.argmax(dim=1)).sum() / len(test_labels)\n",
    "        comp_acc = (predictions_comp.argmax(dim=1) == test_labels.argmax(dim=1)).sum() / len(test_labels)\n",
    "        \n",
    "        real_accs_cur.append(real_acc.item())\n",
    "        comp_accs_cur.append(comp_acc.item())\n",
    "        \n",
    "    real_errors.append(np.array(real_errors_cur))\n",
    "    comp_errors.append(np.array(comp_errors_cur))\n",
    "    \n",
    "    real_accs.append(np.array(real_accs_cur))\n",
    "    comp_accs.append(np.array(comp_accs_cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0350, 1.0335, 1.0503,  ..., 1.0408, 1.0482, 1.0446],\n",
       "        [1.0335, 1.0905, 1.0636,  ..., 1.0582, 1.0623, 1.0697],\n",
       "        [1.0503, 1.0636, 1.1123,  ..., 1.0718, 1.0790, 1.0725],\n",
       "        ...,\n",
       "        [1.0408, 1.0582, 1.0718,  ..., 1.0937, 1.0661, 1.0667],\n",
       "        [1.0482, 1.0623, 1.0790,  ..., 1.0661, 1.1054, 1.0709],\n",
       "        [1.0446, 1.0697, 1.0725,  ..., 1.0667, 1.0709, 1.1228]])"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx_kernel_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0316, 1.0296, 1.0320,  ..., 1.0320, 1.0285, 1.0270],\n",
       "        [1.0296, 1.0930, 1.0491,  ..., 1.0519, 1.0450, 1.0574],\n",
       "        [1.0320, 1.0491, 1.0791,  ..., 1.0518, 1.0460, 1.0450],\n",
       "        ...,\n",
       "        [1.0320, 1.0519, 1.0518,  ..., 1.0839, 1.0421, 1.0472],\n",
       "        [1.0285, 1.0450, 1.0460,  ..., 1.0421, 1.0701, 1.0407],\n",
       "        [1.0270, 1.0574, 1.0450,  ..., 1.0472, 1.0407, 1.0962]])"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx_kernel_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0289, 1.0248, 1.0308,  ..., 1.0321, 1.0252, 1.0259],\n",
       "        [1.0248, 1.0820, 1.0461,  ..., 1.0499, 1.0400, 1.0525],\n",
       "        [1.0308, 1.0461, 1.0828,  ..., 1.0536, 1.0450, 1.0448],\n",
       "        ...,\n",
       "        [1.0321, 1.0499, 1.0536,  ..., 1.0863, 1.0421, 1.0475],\n",
       "        [1.0252, 1.0400, 1.0450,  ..., 1.0421, 1.0677, 1.0395],\n",
       "        [1.0259, 1.0525, 1.0448,  ..., 1.0475, 1.0395, 1.0934]])"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87325]\n",
      "[0.87284999]\n"
     ]
    }
   ],
   "source": [
    "# deg 3 bias 2, lengthscale np.sqrt(d), comp vs real\n",
    "print(np.mean(np.array(real_accs), axis=1))\n",
    "print(np.mean(np.array(comp_accs), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00015419]\n",
      "[0.00011944]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.array(real_errors), axis=1))\n",
    "print(np.mean(np.array(comp_errors), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.857]\n",
      "[0.85765]\n"
     ]
    }
   ],
   "source": [
    "# deg 3 bias 0.5, lengthscale np.sqrt(d), comp vs real\n",
    "print(np.mean(np.array(real_accs), axis=1))\n",
    "print(np.mean(np.array(comp_accs), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00063477]\n",
      "[0.0004947]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.array(real_errors), axis=1))\n",
    "print(np.mean(np.array(comp_errors), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.886]\n",
      "[0.88585]\n"
     ]
    }
   ],
   "source": [
    "# deg 3 bias 1, lengthscale np.sqrt(d), min-max\n",
    "print(np.mean(np.array(real_accs), axis=1))\n",
    "print(np.mean(np.array(comp_accs), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01129104]\n",
      "[0.00356528]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.array(real_errors), axis=1))\n",
    "print(np.mean(np.array(comp_errors), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8777]\n",
      "[0.877]\n"
     ]
    }
   ],
   "source": [
    "# deg 3 bias 1, lengthscale np.sqrt(d), min-max, comp vs real\n",
    "print(np.mean(np.array(real_accs), axis=1))\n",
    "print(np.mean(np.array(comp_accs), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00450897]\n",
      "[0.00314206]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.array(real_errors), axis=1))\n",
    "print(np.mean(np.array(comp_errors), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85329999]\n",
      "[0.8498]\n"
     ]
    }
   ],
   "source": [
    "# deg 3 bias 1, lengthscale np.sqrt(d), no min-max\n",
    "print(np.mean(np.array(real_accs), axis=1))\n",
    "print(np.mean(np.array(comp_accs), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11507457]\n",
      "[0.09992507]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.array(real_errors), axis=1))\n",
    "print(np.mean(np.array(comp_errors), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84925]\n",
      "[0.85265]\n"
     ]
    }
   ],
   "source": [
    "# deg 3 a 2, unit norm\n",
    "print(np.mean(np.array(real_accs), axis=1))\n",
    "print(np.mean(np.array(comp_accs), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10427316]\n",
      "[0.083339]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.array(real_errors), axis=1))\n",
    "print(np.mean(np.array(comp_errors), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86105]\n",
      "[0.86279999]\n"
     ]
    }
   ],
   "source": [
    "# deg 3 a 4, unit norm\n",
    "print(np.mean(np.array(real_accs), axis=1))\n",
    "print(np.mean(np.array(comp_accs), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03144861]\n",
      "[0.01627847]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.array(real_errors), axis=1))\n",
    "print(np.mean(np.array(comp_errors), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
